{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translation_seq2seq_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGi-8foQm7Qk",
        "colab_type": "text"
      },
      "source": [
        "**Hau F05**\n",
        "\n",
        "Mini Assignment: Translate from English to VNese using seq2seq attention model\n",
        "\n",
        "**Refer:**\n",
        "\n",
        "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\n",
        "https://towardsdatascience.com/day-1-2-attention-seq2seq-models-65df3f49e263?gi=c415c036081"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETl7U9zdZk2M",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Prepare Environment"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcZnooEVGuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b32caf06-cede-4e8c-ea17-be14ec44aebe"
      },
      "source": [
        "#mount files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/My Drive/Colab/VTC_Course/Week_6_assignment'\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab/VTC_Course/Week_6_assignment\n",
            "data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WD3N_MLiCgZ",
        "colab_type": "text"
      },
      "source": [
        "Tar data training file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5JVbo25WPb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tar -xzf data/train-en-vi.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaHV3aDraB2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAydG6kRnbg3",
        "colab_type": "text"
      },
      "source": [
        "Import Vietnamese library to import Utils... (remove accents, tokenizer...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmEWbwVXEnQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install underthesea\n",
        "!pip install pyvi \n",
        "from pyvi import ViUtils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HInKh1AHyRhK",
        "colab_type": "text"
      },
      "source": [
        "##Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q8MiN4EpSQc",
        "colab_type": "text"
      },
      "source": [
        "### Define Lang class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhvWtXT8nmxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SoplzRvpjfe",
        "colab_type": "text"
      },
      "source": [
        "Convert to lower case, delete punc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEhTPIbWpXWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = ViUtils.remove_accents(s.lower()).decode(\"utf-8\")\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upj4UC7zqAri",
        "colab_type": "text"
      },
      "source": [
        "Reading file\n",
        "\n",
        "1.   lang1 = source language\n",
        "2.   lang2 = target language\n",
        "\n",
        "reverse = true when translate from lang2 to lang1 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK2VvB5vpzIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readLangs(reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split into lines\n",
        "    lines_lang1 = open(\"data/train.en\", \"r\").read().strip().split('\\n')\n",
        "    lines_lang2 = open(\"data/train.vi\", \"r\").read().strip().split('\\n')\n",
        "    pairs = [[\"\",\"\"]]\n",
        "    for i in range(0,len(lines_lang1)-1):\n",
        "      pairs.append([normalizeString(lines_lang1[i]),normalizeString(lines_lang2[i])])\n",
        "\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(\"vi\")\n",
        "        output_lang = Lang(\"en\")\n",
        "    else:\n",
        "        input_lang = Lang(\"en\")\n",
        "        output_lang = Lang(\"vi\")\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THeFSZ1-rqIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c746ba5f-ae3e-4acc-bda4-7d7342dfc0f1"
      },
      "source": [
        "input_lang, output_lang, pairs = readLangs()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wLysoh9FBrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "e086e3de-0e1e-4f9d-da55-68bf520e7b95"
      },
      "source": [
        "pairs[1:5]"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['rachel pike the science behind a climate headline',\n",
              "  'khoa hoc dang sau mot tieu de ve khi hau'],\n",
              " ['in minutes atmospheric chemist rachel pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change with her team one of thousands who contributed taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n",
              "  'trong phut chuyen gia hoa hoc khi quyen rachel pike gioi thieu so luoc ve nhung no luc khoa hoc miet mai dang sau nhung tieu de tao bao ve bien doi khi hau cung voi doan nghien cuu cua minh hang ngan nguoi da cong hien cho du an nay mot chuyen bay mao hiem qua rung gia de tim kiem thong tin ve mot phan tu then chot .'],\n",
              " ['i apos d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .',\n",
              "  'toi muon cho cac ban biet ve su to lon cua nhung no luc khoa hoc da gop phan lam nen cac dong tit ban thuong thay tren bao .'],\n",
              " ['headlines that look like this when they have to do with climate change and headlines that look like this when they have to do with air quality or smog .',\n",
              "  'co nhung dong trong nhu the nay khi ban ve bien doi khi hau va nhu the nay khi noi ve chat luong khong khi hay khoi bui .']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RVq1DX4x0za",
        "colab_type": "text"
      },
      "source": [
        "Cut-off text for faster\n",
        "\n",
        "Because of not have strong machine my own, so cut-off the data for training faster :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9yffTgnr-50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9WtqVHXyffq",
        "colab_type": "text"
      },
      "source": [
        "### Call prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kLsCfiBko8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs_back_up = pairs"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BHkW-eBxxmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "2bc5b7e4-7692-45d1-eb96-ed4964b24ab2"
      },
      "source": [
        "def prepareData(reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData(False)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 133317 sentence pairs\n",
            "Trimmed to 16602 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "en 8953\n",
            "vi 3328\n",
            "['because it sounds big .', 'boi vi no nghe rat to tat .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaG7_b9-SR1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7cc18a83-b546-4f42-eaca-afd94e5556b6"
      },
      "source": [
        "pairs[1:5]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['and this is the tower from below .', 'va tu duoi dat .'],\n",
              " ['we have to get special flight clearance .',\n",
              "  'phai xin lenh dac biet cho phep bay .'],\n",
              " ['thank you very much .', 'cam on rat nhieu .'],\n",
              " ['you can mimic what you can see .', 'bat chuoc nhung gi ban nhin thay .']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf7NFkB7yMBJ",
        "colab_type": "text"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTYuvUENnxh9",
        "colab_type": "text"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0qiWgbzyoXs",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imu1ndhPyrPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p49UNthQypPA",
        "colab_type": "text"
      },
      "source": [
        "#### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAf_OjoXyl_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrwfaZ7Wn9wp",
        "colab_type": "text"
      },
      "source": [
        "#### Define NN using in seq2seq model (RNN in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o5ijwnjyvPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5UXRAfWy85G",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM96TelTzEGJ",
        "colab_type": "text"
      },
      "source": [
        "Prepare Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suv9H1XUy544",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DshCVpWDzHFk",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAQ5V6wwzAcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqlhJhfozJid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDphxFGdzMAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLNdKyrvzS7y",
        "colab_type": "text"
      },
      "source": [
        "Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-4b7ZrlzQ02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfMN16EzzXYJ",
        "colab_type": "text"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyxGWTnQzUjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dVysFxDzYwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIdEsOy5zdvv",
        "colab_type": "text"
      },
      "source": [
        "**Training and Evaluating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfWI9Twzafy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5e01b88a-4676-4307-a96f-adbd8e7c3ec9"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2m 16s (- 31m 49s) (5000 6%) 4.2040\n",
            "4m 30s (- 29m 18s) (10000 13%) 3.9093\n",
            "6m 45s (- 27m 2s) (15000 20%) 3.7282\n",
            "9m 2s (- 24m 51s) (20000 26%) 3.6448\n",
            "11m 18s (- 22m 37s) (25000 33%) 3.5240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EImchz6ellqF",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afZznHb_lpUa",
        "colab_type": "text"
      },
      "source": [
        "Random evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI2pXmYefEEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt9XhMu8f9J2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "7073a023-ced8-4417-f223-16df71437d18"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"chung ta cach xa ria ty nam anh sang\")\n",
        "attentions.numpy()\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0f81fc7320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH--PUW8m1Hy",
        "colab_type": "text"
      },
      "source": [
        "ShowAttention and how its work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mFJQ3RrfI9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "d459ee3e-0a4e-47e2-8d38-7e592da28218"
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"chung ta cach xa ria ty nam anh sang\")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = chung ta cach xa ria ty nam anh sang\n",
            "output = we are billion light years from the edge . <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W5wu659mpVL",
        "colab_type": "text"
      },
      "source": [
        "Output show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFVpN4JLfTDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "senten"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}